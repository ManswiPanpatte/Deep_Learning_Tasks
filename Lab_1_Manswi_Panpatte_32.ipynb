{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENJ_RyZhsN0G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importing library\n",
        "# Install required libraries (if needed)\n",
        "!pip install pandas numpy scikit-learn\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dljrqu4Fs1pT",
        "outputId": "f29987b4-d48d-4784-ade9-d5495147db71"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def divide_and_shuffle_dataset(file_path, dependent_var, independent_vars, ratios=(0.7, 0.2, 0.1)):\n",
        "    \"\"\"\n",
        "    Divides a dataset into training, validation, and testing datasets after shuffling.\n",
        "\n",
        "    Parameters:\n",
        "        file_path (str): Path to the dataset file (.mat, .csv, .xls).\n",
        "        dependent_var (str): The name of the dependent variable.\n",
        "        independent_vars (list): List of independent variable names.\n",
        "        ratios (tuple): Ratios for training, validation, and testing splits.\n",
        "\n",
        "    Returns:\n",
        "        dict: Contains 'train', 'val', 'test' datasets and corresponding labels.\n",
        "    \"\"\"\n",
        "    # Load the dataset\n",
        "    if file_path.endswith('.csv'):\n",
        "        data = pd.read_csv(file_path)\n",
        "    elif file_path.endswith('.xls') or file_path.endswith('.xlsx'):\n",
        "        data = pd.read_excel(file_path)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Please use .csv or .xls/.xlsx files.\")\n",
        "\n",
        "    # Select only the required columns\n",
        "    columns = independent_vars + [dependent_var]\n",
        "    if not all(col in data.columns for col in columns):\n",
        "        raise ValueError(\"One or more specified columns are not found in the dataset.\")\n",
        "\n",
        "    data = data[columns]\n",
        "\n",
        "    # Shuffle the data\n",
        "    data = shuffle(data, random_state=42).reset_index(drop=True)\n",
        "\n",
        "    # Split into features (X) and labels (y)\n",
        "    X = data[independent_vars].values\n",
        "    y = data[dependent_var].values\n",
        "\n",
        "    # Compute split indices\n",
        "    total_size = len(data)\n",
        "    train_end = int(total_size * ratios[0])\n",
        "    val_end = train_end + int(total_size * ratios[1])\n",
        "\n",
        "    # Split the data\n",
        "    X_train, y_train = X[:train_end], y[:train_end]\n",
        "    X_val, y_val = X[train_end:val_end], y[train_end:val_end]\n",
        "    X_test, y_test = X[val_end:], y[val_end:]\n",
        "\n",
        "    return {\n",
        "        'train': (X_train, y_train),\n",
        "        'val': (X_val, y_val),\n",
        "        'test': (X_test, y_test)\n",
        "    }\n"
      ],
      "metadata": {
        "id": "tGXMdIPVs95U"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set Independent and Dependent Variables\n",
        "dependent_var = 'Traffic fatalities'\n",
        "independent_vars = [\n",
        "    'Urban Population',\n",
        "    'Rural Population',\n",
        "    'Fatalities involving high blood alcohol',\n",
        "    'Licensed drivers (thousands)',\n",
        "    'Registered vehicles (thousands)',\n",
        "    'Vehicle-miles traveled (millions)'\n",
        "]\n"
      ],
      "metadata": {
        "id": "_wIAil4owcAD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Run the Function\n",
        "file_path = '/content/Accidents_with_Label.csv - Accidents_with_Label.csv.csv'  # Update with your file's name\n",
        "\n",
        "# Call the function\n",
        "results = divide_and_shuffle_dataset(\n",
        "    file_path=file_path,\n",
        "    dependent_var=dependent_var,\n",
        "    independent_vars=independent_vars,\n",
        "    ratios=(0.7, 0.2, 0.1)\n",
        ")\n",
        "\n",
        "# Display sizes of each dataset\n",
        "print({key: (len(value[0]), len(value[1])) for key, value in results.items()})\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPnteAdOwjp8",
        "outputId": "28cc8b7e-c933-4533-ba66-660f92dac129"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'train': (35, 35), 'val': (10, 10), 'test': (6, 6)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Inspect the Results\n",
        "# Training dataset\n",
        "X_train, y_train = results['train']\n",
        "print(\"Training Features:\\n\", X_train[:5])  # Display the first 5 rows\n",
        "print(\"Training Labels:\\n\", y_train[:5])    # Display the first 5 labels\n",
        "\n",
        "# Testing dataset\n",
        "X_test, y_test = results['test']\n",
        "print(\"Testing Features:\\n\", X_test[:5])  # Display the first 5 rows\n",
        "print(\"Testing Labels:\\n\", y_test[:5])    # Display the first 5 labels\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNxAQkKRw2bs",
        "outputId": "39f8e6a1-fcf3-4ceb-ae3f-b1bdcf1a1f66"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Features:\n",
            " [[7.4195240e+06 2.5189200e+06 3.6700000e+02 7.1034040e+03 8.6274770e+03\n",
            "  1.0332600e+05]\n",
            " [4.8470750e+06 3.2022380e+06 4.9600000e+02 6.1221370e+03 6.2988360e+03\n",
            "  9.5903000e+04]\n",
            " [1.0910332e+07 1.5089610e+06 5.1700000e+02 8.0576830e+03 9.5076630e+03\n",
            "  1.0913500e+05]\n",
            " [8.5910400e+05 4.3484900e+05 8.1000000e+01 9.4298300e+02 1.3937020e+03\n",
            "  1.4729000e+04]\n",
            " [2.2545660e+06 1.1960880e+06 2.4500000e+02 2.3696210e+03 3.2356400e+03\n",
            "  4.6443000e+04]]\n",
            "Training Labels:\n",
            " [1159 1557 1356  260  774]\n",
            "Testing Features:\n",
            " [[1.388560e+06 1.456098e+06 3.170000e+02 1.896008e+03 1.991650e+03\n",
            "  3.943100e+04]\n",
            " [4.874650e+05 4.147300e+05 1.000000e+02 7.128800e+02 1.056668e+03\n",
            "  1.120700e+04]\n",
            " [7.938850e+06 4.755000e+05 2.270000e+02 5.799532e+03 6.374167e+03\n",
            "  7.284400e+04]\n",
            " [8.333780e+05 9.749660e+05 1.140000e+02 1.292036e+03 1.415954e+03\n",
            "  2.030200e+04]\n",
            " [2.465539e+06 1.981561e+06 3.940000e+02 3.613138e+03 4.588837e+03\n",
            "  5.903500e+04]]\n",
            "Testing Labels:\n",
            " [ 900  229  731  411 1154]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bdlg_sRjxKZ2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}